{"cells":[{"metadata":{"colab":{},"colab_type":"code","id":"JfkorNJrnmNO","trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\ntorch.manual_seed(0) # Set for testing purposes, please do not change!\n\n\ndef show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n    '''\n    Function for visualizing images: Given a tensor of images, number of images, and\n    size per image, plots and prints the images in an uniform grid.\n    '''\n    image_tensor = (image_tensor + 1) / 2\n    image_unflat = image_tensor.detach().cpu()\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    plt.show()","execution_count":1,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"EvO7h0LYnEJZ","trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n        super(Generator, self).__init__()\n        self.z_dim = z_dim\n        # Build the neural network\n        self.gen = nn.Sequential(\n            self.make_gen_block(z_dim, hidden_dim * 4),\n            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n            self.make_gen_block(hidden_dim * 2, hidden_dim),\n            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n        )\n\n    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n        if not final_layer:\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n                nn.BatchNorm2d(output_channels),\n                nn.ReLU(inplace=True)\n            )\n        else: # Final Layer\n            return nn.Sequential(\n                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n                nn.Tanh(),\n\n            )\n\n    def unsqueeze_noise(self, noise):\n        return noise.view(len(noise), self.z_dim, 1, 1)\n\n    def forward(self, noise):\n        x = self.unsqueeze_noise(noise)\n        return self.gen(x)\n\ndef get_noise(n_samples, z_dim, device='cpu'):\n    return torch.randn(n_samples, z_dim, device=device)","execution_count":2,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"aA4AxGnmpuPq","trusted":true},"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, im_chan=1, hidden_dim=16):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            self.make_disc_block(im_chan, hidden_dim),\n            self.make_disc_block(hidden_dim, hidden_dim * 2),\n            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n        )\n\n    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n        if not final_layer:\n            return nn.Sequential(\n                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n                nn.BatchNorm2d(output_channels),\n                nn.LeakyReLU(0.2, inplace=True)\n            )\n        else: # Final Layer\n            return nn.Sequential(\n                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n            )\n    def forward(self, image):\n        disc_pred = self.disc(image)\n        return disc_pred.view(len(disc_pred), -1)","execution_count":5,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"IFLQ039u-qdu","trusted":true},"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\nz_dim = 64\ndisplay_step = 500\nbatch_size = 128\n# A learning rate of 0.0002 works well on DCGAN\nlr = 0.0002\n\n# These parameters control the optimizer's momentum, which you can read more about here:\n# https://distill.pub/2017/momentum/ but you donâ€™t need to worry about it for this course!\nbeta_1 = 0.5 \nbeta_2 = 0.999\ndevice = 'cuda'\n\n# You can tranform the image values to be between -1 and 1 (the range of the tanh activation)\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,)),\n])\n\ndataloader = DataLoader(\n    MNIST('.', download=False, transform=transform),\n    batch_size=batch_size,\n    shuffle=True)","execution_count":8,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"sDFRZ8tg_Y57","trusted":true},"cell_type":"code","source":"gen = Generator(z_dim).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\ndisc = Discriminator().to(device) \ndisc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n\n# You initialize the weights to the normal distribution\n# with mean 0 and standard deviation 0.02\ndef weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    if isinstance(m, nn.BatchNorm2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n        torch.nn.init.constant_(m.bias, 0)\ngen = gen.apply(weights_init)\ndisc = disc.apply(weights_init)","execution_count":9,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"UXptQZcwrBrq","trusted":true},"cell_type":"code","source":"n_epochs = 50\ncur_step = 0\nmean_generator_loss = 0\nmean_discriminator_loss = 0\nfor epoch in range(n_epochs):\n    # Dataloader returns the batches\n    for real, _ in tqdm(dataloader):\n        cur_batch_size = len(real)\n        real = real.to(device)\n\n        ## Update discriminator ##\n        disc_opt.zero_grad()\n        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n        fake = gen(fake_noise)\n        disc_fake_pred = disc(fake.detach())\n        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n        disc_real_pred = disc(real)\n        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n\n        # Keep track of the average discriminator loss\n        mean_discriminator_loss += disc_loss.item() / display_step\n        # Update gradients\n        disc_loss.backward(retain_graph=True)\n        # Update optimizer\n        disc_opt.step()\n\n        ## Update generator ##\n        gen_opt.zero_grad()\n        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n        fake_2 = gen(fake_noise_2)\n        disc_fake_pred = disc(fake_2)\n        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n        gen_loss.backward()\n        gen_opt.step()\n\n        # Keep track of the average generator loss\n        mean_generator_loss += gen_loss.item() / display_step\n\n        ## Visualization code ##\n        if cur_step % display_step == 0 and cur_step > 0:\n            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n            show_tensor_images(fake)\n            show_tensor_images(real)\n            mean_generator_loss = 0\n            mean_discriminator_loss = 0\n        cur_step += 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"C1W2_3: Deep Convolutional GAN (DCGAN) (Student).ipynb","provenance":[]},"coursera":{"schema_names":["GANSC1-2A"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}